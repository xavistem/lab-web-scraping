{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786",
      "metadata": {
        "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786"
      },
      "source": [
        "# Lab | Web Scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce8882fc-4815-4567-92fa-b4816358ba7d",
      "metadata": {
        "id": "ce8882fc-4815-4567-92fa-b4816358ba7d"
      },
      "source": [
        "Welcome to the \"Books to Scrape\" Web Scraping Adventure Lab!\n",
        "\n",
        "**Objective**\n",
        "\n",
        "In this lab, we will embark on a mission to unearth valuable insights from the data available on Books to Scrape, an online platform showcasing a wide variety of books. As data analyst, you have been tasked with scraping a specific subset of book data from Books to Scrape to assist publishing companies in understanding the landscape of highly-rated books across different genres. Your insights will help shape future book marketing strategies and publishing decisions.\n",
        "\n",
        "**Background**\n",
        "\n",
        "In a world where data has become the new currency, businesses are leveraging big data to make informed decisions that drive success and profitability. The publishing industry, much like others, utilizes data analytics to understand market trends, reader preferences, and the performance of books based on factors such as genre, author, and ratings. Books to Scrape serves as a rich source of such data, offering detailed information about a diverse range of books, making it an ideal platform for extracting insights to aid in informed decision-making within the literary world.\n",
        "\n",
        "**Task**\n",
        "\n",
        "Your task is to create a Python script using BeautifulSoup and pandas to scrape Books to Scrape book data, focusing on book ratings and genres. The script should be able to filter books with ratings above a certain threshold and in specific genres. Additionally, the script should structure the scraped data in a tabular format using pandas for further analysis.\n",
        "\n",
        "**Expected Outcome**\n",
        "\n",
        "A function named `scrape_books` that takes two parameters: `min_rating` and `max_price`. The function should scrape book data from the \"Books to Scrape\" website and return a `pandas` DataFrame with the following columns:\n",
        "\n",
        "**Expected Outcome**\n",
        "\n",
        "- A function named `scrape_books` that takes two parameters: `min_rating` and `max_price`.\n",
        "- The function should return a DataFrame with the following columns:\n",
        "  - **UPC**: The Universal Product Code (UPC) of the book.\n",
        "  - **Title**: The title of the book.\n",
        "  - **Price (£)**: The price of the book in pounds.\n",
        "  - **Rating**: The rating of the book (1-5 stars).\n",
        "  - **Genre**: The genre of the book.\n",
        "  - **Availability**: Whether the book is in stock or not.\n",
        "  - **Description**: A brief description or product description of the book (if available).\n",
        "  \n",
        "You will execute this script to scrape data for books with a minimum rating of `4.0 and above` and a maximum price of `£20`. \n",
        "\n",
        "Remember to experiment with different ratings and prices to ensure your code is versatile and can handle various searches effectively!\n",
        "\n",
        "**Resources**\n",
        "\n",
        "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
        "- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
        "- [Books to Scrape](https://books.toscrape.com/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3519921d-5890-445b-9a33-934ed8ee378c",
      "metadata": {
        "id": "3519921d-5890-445b-9a33-934ed8ee378c"
      },
      "source": [
        "**Hint**\n",
        "\n",
        "Your first mission is to familiarize yourself with the **Books to Scrape** website. Navigate to [Books to Scrape](http://books.toscrape.com/) and explore the available books to understand their layout and structure. \n",
        "\n",
        "Next, think about how you can set parameters for your data extraction:\n",
        "\n",
        "- **Minimum Rating**: Focus on books with a rating of 4.0 and above.\n",
        "- **Maximum Price**: Filter for books priced up to £20.\n",
        "\n",
        "After reviewing the site, you can construct a plan for scraping relevant data. Pay attention to the details displayed for each book, including the title, price, rating, and availability. This will help you identify the correct HTML elements to target with your scraping script.\n",
        "\n",
        "Make sure to build your scraping URL and logic based on the patterns you observe in the HTML structure of the book listings!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25a83a0d-a742-49f6-985e-e27887cbf922",
      "metadata": {
        "id": "25a83a0d-a742-49f6-985e-e27887cbf922"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Best of luck! Immerse yourself in the world of books, and may the data be with you!**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0",
      "metadata": {
        "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0"
      },
      "source": [
        "**Important Note**:\n",
        "\n",
        "In the fast-changing online world, websites often update and change their structures. When you try this lab, the **Books to Scrape** website might differ from what you expect.\n",
        "\n",
        "If you encounter issues due to these changes, like new rules or obstacles preventing data extraction, don’t worry! Get creative.\n",
        "\n",
        "You can choose another website that interests you and is suitable for scraping data. Options like Wikipedia, The New York Times, or even library databases are great alternatives. The main goal remains the same: extract useful data and enhance your web scraping skills while exploring a source of information you enjoy. This is your opportunity to practice and adapt to different web environments!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "40359eee-9cd7-4884-bfa4-83344c222305",
      "metadata": {
        "id": "40359eee-9cd7-4884-bfa4-83344c222305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando el scraping...\n",
            "Condiciones: Valoración >= 4 y Precio <= £20\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-1.html\n",
            "  -> ¡Encontrado! 'Set Me Free' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-2.html\n",
            "  -> ¡Encontrado! 'The Four Agreements: A Practical Guide to Personal Freedom' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Sophie's World' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-3.html\n",
            "  -> ¡Encontrado! 'Untitled Collection: Sabbath Poems 2014' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'This One Summer' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Thirst' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-4.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-5.html\n",
            "  -> ¡Encontrado! 'Princess Jellyfish 2-in-1 Omnibus, Vol. 01 (Princess Jellyfish 2-in-1 Omnibus #1)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Princess Between Worlds (Wide-Awake Princess #5)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Outcast, Vol. 1: A Darkness Surrounds Him (Outcast #1)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Mama Tried: Traditional Italian Cooking for the Screwed, Crude, Vegan, and Tattooed' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-6.html\n",
            "  -> ¡Encontrado! 'First and First (Five Boroughs #3)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Camp Midnight' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-7.html\n",
            "  -> ¡Encontrado! 'The Third Wave: An Entrepreneur’s Vision of the Future' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'The Stranger' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-8.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-9.html\n",
            "  -> ¡Encontrado! 'Something More Than This' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Poems That Make Grown Women Cry' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-10.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-11.html\n",
            "  -> ¡Encontrado! 'Dark Notes' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Batman: The Dark Knight Returns (Batman)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Agnostic: A Spirited Manifesto' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-12.html\n",
            "  -> ¡Encontrado! 'Walt Disney's Alice in Wonderland' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-13.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-14.html\n",
            "  -> ¡Encontrado! 'Superman Vol. 1: Before Truth (Superman by Gene Luen Yang #1)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Old School (Diary of a Wimpy Kid #10)' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-15.html\n",
            "  -> ¡Encontrado! 'Lady Midnight (The Dark Artifices #1)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'I Am Pilgrim (Pilgrim #1)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Hyperbole and a Half: Unfortunate Situations, Flawed Coping Mechanisms, Mayhem, and Other Things That Happened' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-16.html\n",
            "  -> ¡Encontrado! 'Greek Mythic History' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Far & Away: Places on the Brink of Change: Seven Continents, Twenty-Five Years' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Eight Hundred Grapes' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Dear Mr. Knightley' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-17.html\n",
            "  -> ¡Encontrado! 'City of Fallen Angels (The Mortal Instruments #4)' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-18.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-19.html\n",
            "  -> ¡Encontrado! 'The Epidemic (The Program 0.6)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'One with You (Crossfire #5)' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-20.html\n",
            "  -> ¡Encontrado! 'The Sleep Revolution: Transforming Your Life, One Night at a Time' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-21.html\n",
            "  -> ¡Encontrado! 'Mother, Can You Not?' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'A Gentleman's Position (Society of Gentlemen #3)' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-22.html\n",
            "  -> ¡Encontrado! 'The Moosewood Cookbook: Recipes from Moosewood Restaurant, Ithaca, New York' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'NaNo What Now? Finding your editing process, revising your NaNoWriMo book and building a writing career through publishing and beyond' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-23.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-24.html\n",
            "  -> ¡Encontrado! 'Roller Girl' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'History of Beauty' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-25.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-26.html\n",
            "  -> ¡Encontrado! 'The Origin of Species' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-27.html\n",
            "  -> ¡Encontrado! 'Naturally Lean: 125 Nourishing Gluten-Free, Plant-Based Recipes--All Under 300 Calories' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Life of Pi' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Every Heart a Doorway (Every Heart A Doorway #1)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Counted With the Stars (Out from Egypt #1)' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-28.html\n",
            "  -> ¡Encontrado! 'The Hobbit (Middle-Earth Universe)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'The Collected Poems of W.B. Yeats (The Collected Works of W.B. Yeats #1)' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-29.html\n",
            "  -> ¡Encontrado! 'Pride and Prejudice' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-30.html\n",
            "  -> ¡Encontrado! 'The Secret Garden' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'The Power Greens Cookbook: 140 Delicious Superfood Recipes' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-31.html\n",
            "  -> ¡Encontrado! 'The Darkest Corners' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Shiver (The Wolves of Mercy Falls #1)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Kill the Boy Band' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-32.html\n",
            "  -> ¡Encontrado! 'Booked' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'An Abundance of Katherines' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-33.html\n",
            "  -> ¡Encontrado! 'A Feast for Crows (A Song of Ice and Fire #4)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'The Gunning of America: Business and the Making of American Gun Culture' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Some Women' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-34.html\n",
            "  -> ¡Encontrado! 'Outlander (Outlander #1)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Night Shift (Night Shift #1-20)' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-35.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-36.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-37.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-38.html\n",
            "  -> ¡Encontrado! 'The Elegant Universe: Superstrings, Hidden Dimensions, and the Quest for the Ultimate Theory' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-39.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-40.html\n",
            "  -> ¡Encontrado! 'Scarlet (The Lunar Chronicles #2)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Running with Scissors' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Ready Player One' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-41.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-42.html\n",
            "  -> ¡Encontrado! 'Green Eggs and Ham (Beginner Books B-16)' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-43.html\n",
            "  -> ¡Encontrado! 'Fifty Shades Freed (Fifty Shades #3)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Disrupted: My Misadventure in the Start-Up Bubble' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-44.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-45.html\n",
            "  -> ¡Encontrado! 'A Visit from the Goon Squad' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'New Moon (Twilight #2)' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-46.html\n",
            "  -> ¡Encontrado! 'Fruits Basket, Vol. 2 (Fruits Basket #2)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'Y: The Last Man, Vol. 1: Unmanned (Y: The Last Man #1)' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'The Zombie Room' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'The Silent Wife' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-47.html\n",
            "  -> ¡Encontrado! 'The Girl You Lost' cumple las condiciones.\n",
            "  -> ¡Encontrado! 'The Edge of Reason (Bridget Jones #2)' cumple las condiciones.\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-48.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-49.html\n",
            "Analizando página: http://books.toscrape.com/catalogue/page-50.html\n",
            "  -> ¡Encontrado! 'A Spy's Devotion (The Regency Spies of London #1)' cumple las condiciones.\n",
            "No hay más páginas. Terminando el bucle.\n",
            "Scraping completado. Creando el DataFrame...\n",
            "Libros encontrados que cumplen las condiciones\n",
            "                 UPC                                              Title  \\\n",
            "0   ce6396b0f23f6ecc                                        Set Me Free   \n",
            "1   6258a1f6a6dcfe50  The Four Agreements: A Practical Guide to Pers...   \n",
            "2   6be3beb0793a53e7                                     Sophie's World   \n",
            "3   657fe5ead67a7767            Untitled Collection: Sabbath Poems 2014   \n",
            "4   51653ef291ab7ddc                                    This One Summer   \n",
            "..               ...                                                ...   \n",
            "70  9c96cd1329fbd82d                                    The Zombie Room   \n",
            "71  b78deb463531d078                                    The Silent Wife   \n",
            "72  4280ac3eab57aa5d                                  The Girl You Lost   \n",
            "73  29fc016c459aeb14              The Edge of Reason (Bridget Jones #2)   \n",
            "74  19fec36a1dfb4c16  A Spy's Devotion (The Regency Spies of London #1)   \n",
            "\n",
            "    Price (£)  Rating  Genre             Availability  \\\n",
            "0       17.46       5  Books  In stock (19 available)   \n",
            "1       17.66       5  Books  In stock (18 available)   \n",
            "2       15.94       5  Books  In stock (18 available)   \n",
            "3       14.27       4  Books  In stock (16 available)   \n",
            "4       19.49       4  Books  In stock (16 available)   \n",
            "..        ...     ...    ...                      ...   \n",
            "70      19.69       5  Books   In stock (1 available)   \n",
            "71      12.34       5  Books   In stock (1 available)   \n",
            "72      12.29       5  Books   In stock (1 available)   \n",
            "73      19.18       4  Books   In stock (1 available)   \n",
            "74      16.97       5  Books   In stock (1 available)   \n",
            "\n",
            "                                          Description  \n",
            "0   Aaron Ledbetter’s future had been planned out ...  \n",
            "1   In The Four Agreements, don Miguel Ruiz reveal...  \n",
            "2   A page-turning novel that is also an explorati...  \n",
            "3   More than thirty-five years ago, when the weat...  \n",
            "4   Every summer, Rose goes with her mom and dad t...  \n",
            "..                                                ...  \n",
            "70  An unlikely bond is forged between three men f...  \n",
            "71  A chilling psychological thriller about a marr...  \n",
            "72  Eighteen years ago your baby daughter was snat...  \n",
            "73  Monday 27 January“7:15 a.m. Hurrah! The wilder...  \n",
            "74  In England’s Regency era, manners and elegance...  \n",
            "\n",
            "[75 rows x 7 columns]\n",
            "\n",
            "El resultado se ha guardado en 'libros_filtrados.csv'\n"
          ]
        }
      ],
      "source": [
        "# Importo las librerías que voy a necesitar\n",
        "import requests  # Para hacer las peticiones a la página web\n",
        "from bs4 import BeautifulSoup  # Para \"entender\" y poder buscar cosas en el HTML\n",
        "import pandas as pd  # Para crear la tabla (DataFrame) al final\n",
        "import time # Para añadir pausas y no saturar el servidor\n",
        "\n",
        "# Definición de la función principal\n",
        "\n",
        "def scrape_books(min_rating, max_price):\n",
        "    \"\"\"\n",
        "    Esta función hace web scraping en la web 'books.toscrape.com'.\n",
        "    Busca libros que cumplan con una valoración mínima y un precio máximo,\n",
        "    y devuelve los datos en un DataFrame de pandas.\n",
        "    \"\"\"\n",
        "\n",
        "    # Diccionario para convertir la clase de la estrella (texto) a un número.\n",
        "    # Por ejemplo, la clase 'star-rating Four' la convertiré al número 4.\n",
        "    rating_map = {\n",
        "        'One': 1,\n",
        "        'Two': 2,\n",
        "        'Three': 3,\n",
        "        'Four': 4,\n",
        "        'Five': 5\n",
        "    }\n",
        "\n",
        "    # Lista donde iré guardando los datos de cada libro que cumpla las condiciones.\n",
        "    lista_libros_ok = []\n",
        "\n",
        "    # Defino la URL base y la primera página por la que empezar.\n",
        "    url_base = 'http://books.toscrape.com/'\n",
        "    # La página 1 no tiene \"page-1.html\", pero las siguientes sí, así que empiezo por la 2 y\n",
        "    # trato la 1 como un caso especial. O mejor, empiezo directamente por la primera página del catálogo.\n",
        "    url_pagina_actual = url_base + 'catalogue/page-1.html'\n",
        "    \n",
        "    print(f\"Iniciando el scraping...\")\n",
        "    print(f\"Condiciones: Valoración >= {min_rating} y Precio <= £{max_price}\")\n",
        "\n",
        "    # Bucle para recorrer todas las páginas del catálogo.\n",
        "    # Usaré un bucle 'while True' que se detendrá cuando no encuentre el botón \"siguiente\".\n",
        "    while True:\n",
        "        print(f\"Analizando página: {url_pagina_actual}\")\n",
        "        \n",
        "        try:\n",
        "            # Hago la petición a la página actual.\n",
        "            respuesta = requests.get(url_pagina_actual)\n",
        "            # Si la página no responde bien, salto a la siguiente iteración.\n",
        "            if respuesta.status_code != 200:\n",
        "                print(f\"Error al acceder a la página {url_pagina_actual}. Saltando...\")\n",
        "                break\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error de conexión: {e}\")\n",
        "            break\n",
        "\n",
        "        # Creo el objeto BeautifulSoup para poder analizar el HTML.\n",
        "        sopa_pagina = BeautifulSoup(respuesta.content, 'html.parser')\n",
        "\n",
        "        # Encuentro todos los libros en la página. Cada libro está en una etiqueta <article>.\n",
        "        libros_en_pagina = sopa_pagina.find_all('article', class_='product_pod')\n",
        "\n",
        "        # Ahora, para cada libro de la página, tengo que entrar en su enlace para ver los detalles.\n",
        "        for libro_articulo in libros_en_pagina:\n",
        "            \n",
        "            # Obtengo el enlace a la página del libro. El enlace es relativo, así que tengo que unirlo a la URL base.\n",
        "            enlace_libro_relativo = libro_articulo.find('h3').find('a')['href']\n",
        "            # Construyo la URL completa para la página del detalle del libro.\n",
        "            url_libro_completa = url_base + 'catalogue/' + enlace_libro_relativo.replace('../', '')\n",
        "\n",
        "            # Hago una pausa pequeña para no sobrecargar el servidor de la página.\n",
        "            time.sleep(0.1) \n",
        "            \n",
        "            # Ahora hago una nueva petición para obtener la página de detalle del libro.\n",
        "            try:\n",
        "                respuesta_libro = requests.get(url_libro_completa)\n",
        "                if respuesta_libro.status_code != 200:\n",
        "                    continue # Si falla, simplemente sigo con el siguiente libro.\n",
        "            except requests.exceptions.RequestException:\n",
        "                continue\n",
        "                \n",
        "            sopa_libro = BeautifulSoup(respuesta_libro.content, 'html.parser')\n",
        "\n",
        "            # Extraigo el precio y la valoración para ver si cumple mis condiciones.\n",
        "            precio_texto = sopa_libro.find('p', class_='price_color').text\n",
        "            precio_float = float(precio_texto.replace('£', '')) # Lo convierto a número\n",
        "\n",
        "            clase_rating = sopa_libro.find('p', class_='star-rating')['class'][1] # La clase es \"star-rating Five\", me quedo con \"Five\"\n",
        "            rating_num = rating_map.get(clase_rating, 0) # Lo convierto a número (si no lo encuentra, pone 0)\n",
        "\n",
        "            # FILTRO\n",
        "            # Compruebo si el libro cumple las condiciones de rating y precio.\n",
        "            if rating_num >= min_rating and precio_float <= max_price:\n",
        "                # Si las cumple, extraigo el resto de la información.\n",
        "                \n",
        "                titulo = sopa_libro.find('h1').text\n",
        "                \n",
        "                # Para UPC, Genre, y Availability, están en una tabla. Tengo que buscar en ella.\n",
        "                tabla = sopa_libro.find('table', class_='table table-striped')\n",
        "                filas_tabla = tabla.find_all('tr')\n",
        "                \n",
        "                upc = filas_tabla[0].find('td').text\n",
        "                genero = filas_tabla[1].find('td').text\n",
        "                disponibilidad = filas_tabla[5].find('td').text\n",
        "                \n",
        "                # La descripción está justo después del div con el id 'product_description'\n",
        "                try:\n",
        "                    descripcion = sopa_libro.find('div', id='product_description').find_next_sibling('p').text\n",
        "                except AttributeError:\n",
        "                    descripcion = \"No disponible\" # Por si algún libro no tiene descripción\n",
        "\n",
        "                # Guardo toda la info en un diccionario\n",
        "                info_libro = {\n",
        "                    'UPC': upc,\n",
        "                    'Title': titulo,\n",
        "                    'Price (£)': precio_float,\n",
        "                    'Rating': rating_num,\n",
        "                    'Genre': genero,\n",
        "                    'Availability': disponibilidad.strip(),\n",
        "                    'Description': descripcion\n",
        "                }\n",
        "                \n",
        "                # Añado el diccionario a mi lista de libros que cumplen las condiciones.\n",
        "                lista_libros_ok.append(info_libro)\n",
        "                print(f\"  -> ¡Encontrado! '{titulo}' cumple las condiciones.\")\n",
        "\n",
        "\n",
        "        # Al final del bucle de los libros, busco el botón \"siguiente\".\n",
        "        siguiente_boton = sopa_pagina.find('li', class_='next')\n",
        "        if siguiente_boton:\n",
        "            # Si existe, construyo la URL de la siguiente página y el bucle 'while' continuará.\n",
        "            enlace_siguiente = siguiente_boton.find('a')['href']\n",
        "            url_pagina_actual = url_base + 'catalogue/' + enlace_siguiente\n",
        "        else:\n",
        "            # Si no hay botón \"siguiente\", significa que hemos llegado al final. Rompo el bucle.\n",
        "            print(\"No hay más páginas. Terminando el bucle.\")\n",
        "            break\n",
        "            \n",
        "    print(\"Scraping completado. Creando el DataFrame...\")\n",
        "\n",
        "    # Con la lista de diccionarios, creo el DataFrame de pandas.\n",
        "    df_resultado = pd.DataFrame(lista_libros_ok)\n",
        "    \n",
        "    return df_resultado\n",
        "\n",
        "# Ejecución del script\n",
        "\n",
        "# Esto es una buena práctica para que el código solo se ejecute cuando corro este archivo directamente.\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    # Defino las condiciones que me pide el lab.\n",
        "    MIN_RATING = 4\n",
        "    MAX_PRICE = 20\n",
        "\n",
        "    # Llamo a mi función para que haga todo el trabajo.\n",
        "    df_libros = scrape_books(min_rating=MIN_RATING, max_price=MAX_PRICE)\n",
        "\n",
        "    # Muestro el resultado final.\n",
        "    print(\"Libros encontrados que cumplen las condiciones\")\n",
        "    print(df_libros)\n",
        "\n",
        "    # Opcional: guardo el resultado en un archivo CSV.\n",
        "    if not df_libros.empty:\n",
        "        df_libros.to_csv('libros_filtrados.csv', index=False)\n",
        "        print(\"\\nEl resultado se ha guardado en 'libros_filtrados.csv'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
